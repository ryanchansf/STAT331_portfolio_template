---
title: "STAT 331 Portfolio"
author: "Ryan Chan"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an **A**.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r}
#| label: wd-1-csv

# Source: Lab 2, Question 1
surveys = read_csv(here::here("data", "surveys.csv"),
                   show_col_types = FALSE)

```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

# Source: Practice Activity 4
military <- read_xlsx(here::here("data",
                                 "gov_spending_per_capita.xlsx"),
                      sheet = "Share of Govt. spending",
                      skip = 7,
                      n_max = 191)

```

-   `txt`

```{r}
#| label: wd-1-txt

# Source: Check-in 2.3
ages_tab <- read_table(file = here::here("Week 2",
                                         "Check-ins",
                                         "Ages_Data",
                                         "ages_tab.txt"))

```

**WD-2: I can select necessary columns from a dataset.**

```{r}
#| label: wd-2

# Source: Challenge 3, Question 1
teacher_evals_compare <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(
    SET_level = ifelse(SET_score_avg >= 4,
                       "excellent", 
                       "standard"),
    sen_level = ifelse(seniority <= 4, 
                       "junior", 
                       "senior")
  ) |>
  select(
    course_id,
    SET_level,
    sen_level
)

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r}
#| label: wd-3-numeric

# Source: Lab 3, Question 9
teacher_evals_clean |>
  group_by(course_id, teacher_id) |>
  summarise(question_count = n_distinct(question_no)) |>
  filter(question_count == 9)

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

# GROWING COMMENT: I strongly recommend against nested functions, as they are difficult for people to understand what your code is doing. Having two lines is not less efficient and is more readable.
# 
# I would recommend first renaming the id column of the person data **and then** piping into inner_join(). It is hard to understand what data are being joined when you are nesting functions inside of functions.

# Source: Lab 5, Step 3
# REVISION: renaming id to membership_id in get_fit_now_member before joining to avoid nested functions
get_fit_now_member <- get_fit_now_member |>
  rename(membership_id = id)

person |>
  inner_join(get_fit_now_member,
             join_by(id == person_id)) |>
  left_join(get_fit_now_check_in,
            join_by(membership_id == membership_id)) |>
  left_join(drivers_license,
            join_by(license_id == id)) |>
  filter(ymd(check_in_date) == ymd(20180109),
         gender == "male",
         membership_status == "gold",
         str_detect(membership_id, "^48Z"),
         str_detect(plate_number, "H42W"))

```

-   factor

```{r}
#| label: wd-3-factor

# Source: Lab 4, Question 2
ca_childcare <- counties |>
  inner_join(childcare_costs,
             by = join_by(county_fips_code)) |>
  filter(state_name == "California")

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

# Source: Lab 5, Step 5
person |>
  inner_join(drivers_license,
             join_by(license_id == id)) |>
  inner_join(facebook_event_checkin,
             join_by(id == person_id)) |>
  filter(gender == "female",
         hair_color == "red",
         height %in% c(65:67),
         car_make == "Tesla",
         car_model == "Model S",
         event_name == "SQL Symphony Concert",
         month(ymd(date)) == 12,
         year(ymd(date)) == 2017) |>
  group_by(id) |>
  summarize(concert_attendance = n()) |>
  filter(concert_attendance == 3)

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

```{r}
#| label: wd-4-numeric

# REVISION AFTER MIDTERM: 

# Source: Challenge 3, Question 1
# REVISION: since question numbers are all in the 900s, subtracting 900 from each in order to refer to them by their single/double digit identifier
teacher_evals_compare <- teacher_evals |>
  mutate(
    question_no = question_no - 900,
    SET_level = ifelse(SET_score_avg >= 4,
                       "excellent", 
                       "standard"),
    sen_level = ifelse(seniority <= 4, 
                       "junior", 
                       "senior")
  ) |>
  filter(question_no == 3) |>
  select(
    course_id,
    SET_level,
    sen_level
)

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

# REVISION AFTER MIDTERM: using my own example that uses str_detect() against a specified regex

# Source: Lab 5, Step 2
# REVISION: increasing efficiency by directly extracting the max of all addresses
# get both witnesses and their interview transcripts
person |>
  filter(
    (address_street_name == "Northwestern Dr" & 
       address_number == max(address_number)) |
    (address_street_name == "Franklin Ave" & 
       str_detect(name, "^Annabel"))) |>
  left_join(interview,
            join_by(id == person_id)) |>
  select(id,
         name,
         transcript)

```

-   factor (example must use functions from **forcats**)

```{r}
#| label: wd-4-factor

# Source: Lab 4, Question 3
ca_childcare <- ca_childcare |> 
  mutate(county_name = str_remove(county_name, " County"),
         region = fct_collapse(county_name,
                               "Superior California" = c("Butte", "Colusa", "El Dorado", "Glenn", "Lassen", "Modoc", "Nevada", "Placer", "Plumas", "Sacramento", "Shasta", "Sierra", "Siskiyou", "Sutter", "Tehama", "Yolo", "Yuba"),
                               "North Coast" = c("Del Norte", "Humboldt", "Lake", "Mendocino", "Napa", "Sonoma", "Trinity"),
                               "San Francisco Bay Area" = c("Alameda", "Contra Costa", "Marin", "San Francisco", "San Mateo", "Santa Clara", "Solano"),
                               "Northern San Joaquin Valley" = c("Alpine", "Amador", "Calaveras", "Madera", "Mariposa", "Merced", "Mono", "San Joaquin", "Stanislaus", "Tuolumne"),
                               "Central Coast" = c("Monterey", "San Benito", "San Luis Obispo", "Santa Barbara", "Santa Cruz", "Ventura"),
                               "Southern San Joaquin Valley" = c("Fresno", "Inyo", "Kern", "Kings", "Tulare"),
                               "Inland Empire" = c("Riverside", "San Bernardino"),
                               "Los Angeles County" = c("Los Angeles"),
                               "Orange County" = c("Orange"),
                               "San Diego-Imperial" = c("San Diego", "Imperial")))
```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

# Source: Lab 5, Step 1
# REVISION: converting date column into a date-time variable
crime_scene_report |>
  mutate(date = ymd(date)) |>
  filter(city == "SQL City",
         date == ymd(20180115),
         type == "murder") |>
  pull(description)

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r}
#| label: wd-5-left

# Source: Lab 5, Step 6
person |>
  left_join(interview,
            join_by(id == person_id)) |>
  filter(id == 99716) |>
  select(name,
         transcript)

```

-   `right_join()`

```{r}
#| label: wd-5-right

# N/A

```

-   `inner_join()`

```{r}
#| label: wd-5-inner

# Source: Lab 5, Step 4
person |>
  inner_join(interview,
             join_by(id == person_id)) |>
  filter(id == 67318) |>
  pull(transcript)

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

# N/A

```

-   `anti_join()`

```{r}
#| label: wd-6-anti

# N/A
# if I want to do a !%in% (don't want observation that are included in this list)

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

# REVISION AFTER MIDTERM: removing multiple calls to is.na() and replacing with one call to drop_na()
# REVISION AFTER MIDTERM: using fct_reorder2() to order legend instead of hardcoding order

# Source: Lab 4, Question 6
# data cleaning before piping into the plot
ca_childcare |>
  drop_na(mc_infant,
          mc_toddler,
          mc_preschool) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_group",
               values_to = "weekly_price") |>
  mutate(age_group = factor(age_group,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool"))) |>
  # create the plot
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       # reorder legend
                       color = fct_reorder2(.f = region,
                                           .x = study_year,
                                           .y = weekly_price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  facet_wrap(~ age_group) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region") +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500),
                     labels = label_currency(prefix = "$", # adding $ to y-axis labels
                                             accuracy = 1)) +
  theme(legend.position = "right",
        strip.background = element_rect(color = "black"),
        panel.border = element_rect(color = "black",
                                    fill = NA), # black border around each plot
        aspect.ratio = 1.1,
        axis.text = element_text(size = 6)
  )

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

# REVISION AFTER MIDTERM: making column names more descriptive

# Source: Lab 4, Question 4
ca_childcare |>
  group_by(region, study_year) |>
  filter(study_year %in% c(2008, 2018)) |>
  summarize(median_mhi = median(mhi_2018,
                                na.rm = TRUE)) |>
  pivot_wider(names_from = study_year,
              values_from = median_mhi,
              names_glue = "Median household income in {study_year}") |>
  arrange(desc(`Median household income in 2018`))

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

-   Labs 1-5

-   Challenges 1-3

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

# Source: Lab 2, Question 4
ggplot(data = surveys) +
  geom_point(mapping = aes(x = weight,
                           y = hindfoot_length),
             position = "jitter",
             alpha = 0.5) +
  # facet the plot by species
  facet_wrap(~species) +
  labs(x = "Weight (g)",
       y = "",
       title = "Relationship between Weight and Hindfoot Length in Rodent Species from Portal, AZ",
       subtitle = "Hindfoot Length (mm)")

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

# Source: Challenge 3, Question 1
teacher_evals_compare <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(SET_level = ifelse(SET_score_avg >= 4,
                       "excellent", 
                       "standard"),
         sen_level = ifelse(seniority <= 4, 
                       "junior", 
                       "senior")
  ) |>
  select(
    course_id,
    SET_level,
    sen_level
  )

```

-   Example of function formatting

```{r}
#| label: r-2-3

# Source: Challenge 7, Lab 2
# REVISION: optimize conditionals by replacing ifelse() with case_when()
filter_measurements <- function(vec, lower, upper) {
  return(case_when(vec >= lower ~ vec,
                   vec <= upper ~ vec,
                   .default = NA))
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

```{r}
#| label: r-3-example

# Source: Lab 4, Question 5
ca_childcare |>
  group_by(region) |>
  filter(study_year == 2018) |>
  summarize(median_mc = median(mc_infant,
                               na.rm = TRUE)) |>
  # get the minimum median, resistant to changes in data set
  slice_min(median_mc)

```

-   Example of function stops

```{r}
#| label: r-3-function-stops

# Source: Challenge 7, Question 4
# REVISION: adding function stops to enforce input validation on parameters
condition_index <- function(length, weight) {
  # validate parameters
  stopifnot("Error: length must be a positive numeric value" = is.numeric(length) & length > 0,
            "Error: weight must be a positive numeric value" = is.numeric(weight) & weight > 0)
  
  return(100 * (weight / (length^3)))
}

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

```{r}
#| label: dvs-1-num

# Source: Lab 2, Question 4
ggplot(data = surveys) +
  geom_point(mapping = aes(x = weight,
                           y = hindfoot_length),
             position = "jitter",
             alpha = 0.5
  ) +
  facet_wrap(~species) +
  labs(x = "Weight (g)",
       y = "",
       title = "Relationship between Weight and Hindfoot Length in Species from Portal, AZ",
       subtitle = "Hindfoot Length (mm)",
  )

```

-   at least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

# REVISION AFTER MIDTERM: remove 45º axis label to avoid head tilt

# Source: Lab 2, Question 16
ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = species)
       ) +
  geom_jitter(color = "steelblue",
              alpha = 0.5,
              show.legend = FALSE) +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight (g)",
       y = "",
       subtitle = "Species",
       title = "Weight Distribution Across Rodent Species from Portal, Arizona")

```

-   at least two categorical variables

```{r}
#| label: dvs-2-cat

# Source: Challenge 3, Question 2
ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level,
                     fill = SET_level)
       ) +
  geom_bar(position = "stack") +
  labs(
    x = "Seniority of Instructor",
    y = "",
    subtitle = "Number of Sections"
  ) +
  scale_fill_manual(
    values = c("steelblue", "orange3")
  )

```

-   dates (timeseries plot)

```{r}
#| label: dvs-2-date

# REVISION AFTER MIDTERM: removing multiple calls to is.na() and replacing with one call to drop_na()
# REVISION AFTER MIDTERM: using fct_reorder2() to order legend instead of hardcoding order

# Source: Lab 4, Question 6
# data cleaning before piping into the plot
ca_childcare |>
  drop_na(mc_infant,
          mc_toddler,
          mc_preschool) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_group",
               values_to = "weekly_price") |>
  mutate(age_group = factor(age_group,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool"))) |>
  # create the plot
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       # reorder legend
                       color = fct_reorder2(.f = region,
                                           .x = study_year,
                                           .y = weekly_price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  facet_wrap(~ age_group) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region") +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500),
                     labels = label_currency(prefix = "$", # adding $ to y-axis labels
                                             accuracy = 1)) +
  theme(legend.position = "right",
        strip.background = element_rect(color = "black"),
        panel.border = element_rect(color = "black",
                                    fill = NA), # black border around each plot
        aspect.ratio = 1.1,
        axis.text = element_text(size = 6)
  )

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

```{r}
#| label: dvs-2-1

# REVISION AFTER MIDTERM: remove 45º axis label to avoid head tilt

# Source: Lab 2, Question 16
ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = species)
       ) +
  geom_jitter(color = "steelblue",
              alpha = 0.5,
              show.legend = FALSE) +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight (g)",
       y = "",
       subtitle = "Species",
       title = "Weight Distribution Across Rodent Species from Portal, Arizona")

```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-2

# REVISION AFTER MIDTERM: remove 45º axis label to avoid head tilt

# Source: Lab 2, Question 16
ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = species)
       ) +
  geom_jitter(color = "steelblue",
              alpha = 0.5,
              show.legend = FALSE) +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight (g)",
       y = "",
       subtitle = "Species",
       title = "Weight Distribution Across Rodent Species from Portal, Arizona")

```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-3

# REVISION AFTER MIDTERM: removing multiple calls to is.na() and replacing with one call to drop_na()
# REVISION AFTER MIDTERM: using fct_reorder2() to order legend instead of hardcoding order

# Source: Lab 4, Question 6
# data cleaning before piping into the plot
ca_childcare |>
  drop_na(mc_infant,
          mc_toddler,
          mc_preschool) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_group",
               values_to = "weekly_price") |>
  mutate(age_group = factor(age_group,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool"))) |>
  # create the plot
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       # reorder legend
                       color = fct_reorder2(.f = region,
                                           .x = study_year,
                                           .y = weekly_price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  facet_wrap(~ age_group) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region") +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500),
                     labels = label_currency(prefix = "$", # adding $ to y-axis labels
                                             accuracy = 1)) +
  theme(legend.position = "right",
        strip.background = element_rect(color = "black"),
        panel.border = element_rect(color = "black",
                                    fill = NA), # black border around each plot
        aspect.ratio = 1.1,
        axis.text = element_text(size = 6)
  )

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

```{r}
#| label: dvs-3-1

# Source: Challenge 7, Question 5

# Source for theme elements:
# - https://ggplot2.tidyverse.org/reference/element.html
# - https://ggplot2.tidyverse.org/reference/scale_manual.html

# REVISION:
# - adding unique colors to individual facets
# - filtering out NA values before condition index calculated
# - removing legend to reduce redundancy
# - properly orienting axis labels
# - adding personal preferences for plot styling with theme()

fish |>
  drop_na(length,
          weight) |>
  # calculate condition indices for fish
  mutate(condition_index = condition_index(length,
                                           weight)) |>
  # plot condition index over time by species
  ggplot(aes(x = year, 
             y = condition_index, 
             color = species)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = "loess", 
              se = FALSE, 
              linewidth = 0.8) +
  labs(title = "Blackfoot River Trout Condition Index Over Time by Species",
       x = "Year",
       y = "",
       subtitle = "Condition Index",
       color = "Species") +
  # facet by species
  facet_wrap(~ species, 
             scales = "free_y") +
  # custom point colors for each species
  facet_wrap(~ species, scales = "free_y") +
  scale_color_manual(values = c("Brown" = "darkseagreen3", 
                               "Bull" = "orchid2", 
                               "RBT" = "indianred1", 
                               "WCT" = "dodgerblue1")) +
  theme_minimal() +
  # add additional styling to plot theme
  theme(plot.title = element_text(size = 16, 
                                  face = "bold", 
                                  family = "Verdana"),
        plot.subtitle = element_text(size = 13,
                                     family = "Verdana"),
        axis.title = element_text(size = 13,
                                  family = "Verdana"),
        axis.text = element_text(size = 10,
                                 family = "Verdana"),
        strip.background = element_rect(fill = "papayawhip",
                                        color = "gray30"),
        strip.text = element_text(size = 10,
                                  face = "italic",
                                  family = "Verdana"),
        panel.border = element_rect(color = "gray30",
                                    fil = NA),
        legend.position = "none")

```

-   I can use annotations

```{r}
#| label: dvs-3-2

# Source: Challenge 7, Question 5

# REVISION AFTER MIDTERM: removing multiple calls to is.na() and replacing with one call to drop_na()
# REVISION AFTER MIDTERM: using fct_reorder2() to order legend instead of hardcoding order

# Source: Lab 4, Question 6

# data cleaning before piping into the plot
# annotations: using the label_currency() function to annotate y-axis labels with $
ca_childcare |>
  drop_na(mc_infant,
          mc_toddler,
          mc_preschool) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_group",
               values_to = "weekly_price") |>
  mutate(age_group = factor(age_group,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool"))) |>
  # create the plot
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       # reorder legend
                       color = fct_reorder2(.f = region,
                                           .x = study_year,
                                           .y = weekly_price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  facet_wrap(~ age_group) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region") +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500),
                     labels = label_currency(prefix = "$", # adding $ to y-axis labels
                                             accuracy = 1)) +
  theme(legend.position = "right",
        strip.background = element_rect(color = "black"),
        panel.border = element_rect(color = "black",
                                    fill = NA), # black border around each plot
        aspect.ratio = 1.1,
        axis.text = element_text(size = 6)
  )

```

-   I can be creative...

```{r}
#| label: dvs-3-3

# Source for theme elements:
# - https://ggplot2.tidyverse.org/reference/element.html
# - https://ggplot2.tidyverse.org/reference/scale_manual.html

# REVISION:
# - adding unique colors to individual facets
# - filtering out NA values before condition index calculated
# - removing legend to reduce redundancy
# - properly orienting axis labels
# - adding personal preferences for plot styling with theme()

fish |>
  drop_na(length,
          weight) |>
  # calculate condition indices for fish
  mutate(condition_index = condition_index(length,
                                           weight)) |>
  # plot condition index over time by species
  ggplot(aes(x = year, 
             y = condition_index, 
             color = species)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = "loess", 
              se = FALSE, 
              linewidth = 0.8) +
  labs(title = "Blackfoot River Trout Condition Index Over Time by Species",
       x = "Year",
       y = "",
       subtitle = "Condition Index",
       color = "Species") +
  # facet by species
  facet_wrap(~ species, 
             scales = "free_y") +
  # custom point colors for each species
  facet_wrap(~ species, scales = "free_y") +
  scale_color_manual(values = c("Brown" = "darkseagreen3", 
                               "Bull" = "orchid2", 
                               "RBT" = "indianred1", 
                               "WCT" = "dodgerblue1")) +
  theme_minimal() +
  # add additional styling to plot theme
  theme(plot.title = element_text(size = 16, 
                                  face = "bold", 
                                  family = "Verdana"),
        plot.subtitle = element_text(size = 13,
                                     family = "Verdana"),
        axis.title = element_text(size = 13,
                                  family = "Verdana"),
        axis.text = element_text(size = 10,
                                 family = "Verdana"),
        strip.background = element_rect(fill = "papayawhip",
                                        color = "gray30"),
        strip.text = element_text(size = 10,
                                  face = "italic",
                                  family = "Verdana"),
        panel.border = element_rect(color = "gray30",
                                    fil = NA),
        legend.position = "none")

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

# REVISION AFTER MIDTERM: making column names more descriptive

# Source: Lab 4, Question 4
ca_childcare |>
  group_by(region, study_year) |>
  filter(study_year %in% c(2008, 2018)) |>
  summarize(median_mhi = median(mhi_2018,
                                na.rm = TRUE)) |>
  pivot_wider(names_from = study_year,
              values_from = median_mhi,
              names_glue = "Median household income in {study_year}") |>
  arrange(desc(`Median household income in 2018`))

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

# Source: Lab 3, Question 6
# REVISION: utilized across() to summarize distinct counts for teacher_id and course_id columns
num_instructors <- teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id,
                             course_id),
                   .fns = n_distinct,
                   .names = "unique_{.col}s"))

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

# Source: Lab 3, Question 8
teacher_evals_clean |>
  group_by(academic_degree, sex) |>
  summarise(avg_seniority = mean(seniority),
            total_instructors = n_distinct(teacher_id))

```

-   Example 2

```{r}
#| label: dvs-5-2

# Source: Lab 3, Question 9
# REVISION: making output more concise by summarizing information necessary to answer question
teacher_evals_clean |>
  group_by(course_id, teacher_id) |>
  summarise(question_count = n_distinct(question_no), 
            .groups = "drop") |>
  filter(question_count == 9) |>
  count()

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r}
#| label: dvs-6-1

# Source: Lab 3, Question 6
# create new df with counts for each
num_instructors <- teacher_evals_clean |>
  summarise(unique_instructors = n_distinct(teacher_id),
            unique_courses = n_distinct(course_id),
            unique_combos = n_distinct(teacher_id, course_id))

num_instructors

```

-   Example 2

```{r}
#| label: dvs-6-2

# Source: Lab 3, Question 8
teacher_evals_clean |>
  group_by(academic_degree, sex) |>
  summarise(
    avg_seniority = mean(seniority),
    total_instructors = n_distinct(teacher_id)
  )

```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r}
#| label: dvs-7-1

# Source: Lab 9, Question 2
# REVISION: added additional styling to the gt table
# Sources for gt styling and configuration: 
# - https://chatgpt.com/c/67554333-4c54-800b-af6c-14b149e3bf8d
# - https://gt.rstudio.com/reference/opt_table_font.html
# - https://gt.rstudio.com/reference/opt_table_outline.html

results_df |>
  count(ncorrect) |>
  mutate(proportion = n / sum(n)) |>
  select(ncorrect,
         proportion) |>
  pivot_wider(names_from = ncorrect,
              values_from = proportion,
              names_prefix = "Babies_") |>
  gt() |>
  # bold and italicize title and subtitle
  tab_header(title = md("**Percentage of Correct Baby Assignments**"),
             subtitle = md("*10,000 Simulations*")) |>
  fmt_percent() |>
  # add descriptive column labels
  cols_label(
    Babies_0 = "0 Correct Babies",
    Babies_1 = "1 Correct Baby",
    Babies_2 = "2 Correct Babies",
    Babies_4 = "4 Correct Babies"
  ) |>
  opt_table_outline() |>
  opt_table_font(font = "Georgia") |>
  # add color and borders to column labels
  tab_style(style = list(cell_fill(color = "honeydew2"),
                         cell_borders(sides = "right",
                                      color = "gray14",
                                      weight = px(3))),
            locations = cells_column_labels()) |>
  # add color and borders to row data
  tab_style(style = list(cell_fill(color = "slategray1"),
                         cell_borders(sides = "right",
                                      color = "gray14",
                                      weight = px(3))),
            locations = cells_body())


```

-   Example 2

```{r}
#| label: dvs-7-2

# Source: Lab 9, Question 7
# REVISION: added additional styling to the gt table
# Sources for gt styling and configuration: 
# - https://chatgpt.com/c/67554333-4c54-800b-af6c-14b149e3bf8d
# - https://gt.rstudio.com/reference/opt_table_font.html
# - https://gt.rstudio.com/reference/opt_table_outline.html
# Source for manipulating row colors using log10(): https://www.rdocumentation.org/packages/SparkR/versions/2.1.2/topics/log10

# table to summarize the means across each sample size
all_simulations |>
  group_by(n) |>
  summarise(mean_of_means = mean(simulated_means)) |>
  gt() |>
  tab_header(title = md("**Summary of Simulated Means**"),
             subtitle = md("*Comparison Across Different Sample Sizes*")) |>
  # add descriptive column names
  cols_label(n = "Sample Size",
             mean_of_means = "Mean of Simulated Means") |>
  opt_table_outline() |>
  opt_table_font(font = "Georgia") |>
  # add color and borders to column labels
  tab_style(style = list(cell_fill(color = "lightsalmon1"),
                         cell_borders(sides = "right",
                                      color = "gray14",
                                      weight = px(3))),
            locations = cells_column_labels()) |>
  # add color and borders to row data
  tab_style(style = cell_borders(sides = "right",
                                  color = "gray14",
                                  weight = px(3)),
            locations = cells_body()) |>
  # alternate colors for rows by sample size
  tab_style(style = cell_fill(color = "lightcyan1"),
            locations = cells_body(rows = log10(n) %% 2 == 0)) |>
  tab_style(style = cell_fill(color = "lightskyblue1"),
            locations = cells_body(rows = log10(n) %% 2 == 1))

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

# Source: Lab 5, Step 1
crime_scene_report |>
  filter(city == "SQL City",
         ymd(date) == ymd(20180115),
         type == "murder") |>
  pull(description)

```

-   `across()`

```{r}
#| label: pe-1-across

# Source: Lab 3, Question 6
# REVISION: utilized across() to summarize distinct counts for teacher_id and course_id columns
num_instructors <- teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id,
                             course_id),
                   .fns = n_distinct,
                   .names = "unique_{.col}s"))

```

-   `map()` functions

```{r}
#| label: pe-1-map-1

# Source: Lab 8, Question 4 
missing_vals <- map_int(.x = fish,
                        .f = ~ sum(is.na(.)))
tibble(variable = names(fish),
       count = missing_vals) |>
  pivot_wider(names_from = variable,
              values_from = count) |>
  # table formatting
  kable() |>
  kable_styling() |>
  row_spec(1,
           background = "lightgray")

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

```{r}
#| label: pe-2-1

# Source: Challenge 7, Lab 2
# REVISION: optimize conditionals by replacing ifelse() with case_when()
filter_measurements <- function(vec, lower, upper) {
  return(case_when(vec >= lower ~ vec,
                   vec <= upper ~ vec,
                   .default = NA))
}

```

-   Function that operates on data frames

```{r}
#| label: pe-2-2

# Source: Lab 3, Question 5
# REVISION: adding a function to convert columns to character types

convert_to_char <- function(df, cols) {
  return(df |>
           mutate(across(.cols = {{ cols }},
                         .fns = as.character)))
}

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  # convert to proper character types
  convert_to_char(cols = c("teacher_id",
                           "course_id")) |>
  select(course_id,
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
         )

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r}
#| label: pe-3-across

# Source: Lab 3, Question 6
# REVISION: utilized across() to summarize distinct counts for teacher_id and course_id columns
num_instructors <- teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id,
                             course_id),
                   .fns = n_distinct,
                   .names = "unique_{.col}s"))

```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

# Source: Lab 8, Question 4 
missing_vals <- map_int(.x = fish,
                        .f = ~ sum(is.na(.)))
tibble(variable = names(fish),
       count = missing_vals) |>
  pivot_wider(names_from = variable,
              values_from = count) |>
  # table formatting
  kable() |>
  kable_styling() |>
  row_spec(1,
           background = "lightgray")

```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

# Source: Lab 9, Question 6

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df), 
                                .f = simulate_means)
         ) |> 
  unnest(cols = simulated_means) 
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

# Source: Lab 3, Question 7
# REVISION: fixing function syntax and adding named arguments
# unique teacher-course combinations with any column being NA
teacher_evals_clean |>
  group_by(course_id, 
           teacher_id) |>
  filter(if_any(.cols = everything(),
                .fns = ~ is.na(.x)))

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

# REVISION AFTER MIDTERM: removing multiple calls to is.na() and replacing with one call to drop_na()
# REVISION AFTER MIDTERM: using fct_reorder2() to order legend instead of hardcoding order

# Source: Lab 4, Question 6
# data cleaning before piping into the plot
ca_childcare |>
  drop_na(mc_infant,
          mc_toddler,
          mc_preschool) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_group",
               values_to = "weekly_price") |>
  mutate(age_group = factor(age_group,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool"))) |>
  # create the plot
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       # reorder legend
                       color = fct_reorder2(.f = region,
                                           .x = study_year,
                                           .y = weekly_price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  facet_wrap(~ age_group) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region") +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500),
                     labels = label_currency(prefix = "$", # adding $ to y-axis labels
                                             accuracy = 1)) +
  theme(legend.position = "right",
        strip.background = element_rect(color = "black"),
        panel.border = element_rect(color = "black",
                                    fill = NA), # black border around each plot
        aspect.ratio = 1.1,
        axis.text = element_text(size = 6)
  )

```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

# Source: Lab 9, Question 1
# simulate random samples
randomBabies <- function(nBabies){
  assignment <- sample(1:nBabies,
                       size = nBabies)
  # compare random assignment with original order
  return(sum(assignment == 1:nBabies))
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(4)
                   )

```

-   Example 2

```{r}
#| label: dsm-1-2

# Source: Lab 9, Question 4, 5, 6
# simulate sample means for Chi-squared distribution
simulate_means <- function(n, df){
  map_dbl(.x = 1:n, 
          .f = ~rchisq(n = 100,
                       df = df) |> mean()
          )
}

grid <- crossing(n = c(10,
                       100,
                       1000,
                       10000), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df), 
                                .f = simulate_means)
         ) |> 
  unnest(cols = simulated_means)

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

# REVISION AFTER MIDTERM: performing chi-squared test without creating contingency table

# Source: Challenge 3, Question 3
chisq.test(x = teacher_evals_compare$SET_level,
           y = teacher_evals_compare$sen_level)

# Since the p-value = 0.001997, which is less than 0.05, we reject the null hypothesis. Thus, we conclude that there is a significant association between the SET_level, or the evaluation level, and the sen_level, or seniority level, and that the SET_level is not independent of the seniority level of the instructors. This means that seniority is likely a significant factor in the evaluation scores for instructors.

```

-   Example 2

```{r}
#| label: dsm-2-2

# Source: Lab 2, Question 17
# ANOVA test
species_mod <- aov(weight ~ species, 
                   data = surveys)

summary(species_mod)

# Since the p-value is significantly less than 0.05, we reject the null hypothesis that the population mean weight is the same between all fourteen rodent species. Thus, there is strong evidence to suggest that at least one rodent species has a different population mean weight in comparison to the others.

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I demonstrated revisions in thinking through lab revisions throughout the course. Notably, one of the things that I struggled with to begin was remaining consistent with my code formatting. In the earlier assignments (i.e. Lab 1, 2), I struggled with consistent standards such as indentation, spacing, newlines. Additionally, I initially lacked in my correlation with problems in labs/challenges to the learning targets in mind. Through constructive feedback, I was able to adjust the way I think about the problems and envision the learning targets meant to be gauged at each problem. In this sense, I've been able to take feedback in stride and be more conscious about the ways in which my code reflects different abilities, such as code tidiness, effective use of functions, reducing code redundancy, and creating descriptive statistics. The code examples provided in my portfolio exhibit some of the ways in which I have revised my thinking with respect to formatting, increasingly descriptive graphs and plots, and overall writing code that is easy to comprehend.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

Revisions and growing comments are indicated in ALL CAPS in the comments above the code chunk.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

So far, I've been able to extend my thinking through lab and challenge assignments. Specifically, in Challenge 3, I was able to extend my thinking by applying the context of the data set of interest to my own experiences to further analyze correlation between variables. In that assignment, I considered additional variables that could provide even better statistical analysis to represent the relationships in a study on teachers, students, and their evaluations. I also extended my thinking by challenging myself to add additional features to graphs/plots that could enhance the story told by it. For instance, in Lab 4, I utilized an additional package to add dollar signs to axis labels, making the plot more descriptive and comprehensible.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

Lab 4 Code Review:

"Hi Emi! Great job on Lab 4. A few notes:\

First of all, your description of the dataset in question 1 was highly detailed, and I admire how you referenced specifically where the data came from. I noticed you used single quotes (') around some of your variable names: if you wanted to make those highlighted in your html, you could use backticks instead (e.g. \`childcare_costs\` as opposed to 'childcare_costs').\

At a first glance, your code styling overall looks easy to digest. One suggestion I would have is to be a little bit more consistent with your spacing and newlines. Particularly, in question 4, I think you did a great job with spacing out each function in the pipeline into new lines, but in question 6, you might benefit by making sure all of the pipeline functions are aligned/spaced properly. The same applies to newlines in the function arguments; in question 6, you added new lines for every new argument, but in other code chunks you did all arguments in one line. This is a pretty minor thing, but I think it could be easily fixed!\

That being said, I feel you did a good job recreating the plot. While you didn't quite get the order of the regions the same in the legend, you were able to emulate the ranges x and y scales well. Next time, you can even an add a call to theme() in your plot and specify an aspect ratio to make the graphs more squared.\

Overall, great job with this lab Emi!"

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

Through our class practice activities, I have been able to exercise my skills as both an ideator and active listener. The pair programming activities have allowed me to improve my ability to communicate thoughts verbally, allowing both myself and my partner to better understand concepts together. This has been beneficial, as it's taught me the value in sharing thoughts rather than simpkly outputting everything that comes to mind. In programming, collaboration is paramount; I've learned to work in such a way that allows both partners to understand and contribute effectively.
